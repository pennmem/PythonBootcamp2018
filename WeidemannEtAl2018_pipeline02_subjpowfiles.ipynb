{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "from glob import glob\n",
    "\n",
    "run_on_rhino = True\n",
    "\n",
    "if run_on_rhino:\n",
    "    rhino_mount = ''\n",
    "else:\n",
    "    rhino_mount = '/home/ctw/fusemounts/rhino'\n",
    "\n",
    "\n",
    "# expfolder = 'RAM_FR'\n",
    "expfolder = 'RAM_catFR'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_root = '/scratch/cweidema/bootcamp/tmpdat'\n",
    "sesspow_path = rhino_mount+output_root+'/RAM/'+expfolder+'/'+expfolder+'1_power/encoding/hdf5_files_sess/'\n",
    "subjpow_path = rhino_mount+output_root+'/RAM/'+expfolder+'/'+expfolder+'1_power/encoding/hdf5_files_subj/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pow_suffix='.hdf5'\n",
    "sesspaths = np.sort(glob(os.path.join(sesspow_path,'*'+pow_suffix)))\n",
    "subj_done = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  R1375C\n",
      "/scratch/cweidema/bootcamp/tmpdat/RAM/RAM_catFR/RAM_catFR1_power/encoding/hdf5_files_sess/pow_R1375C_1_allleads.hdf5\n",
      "/scratch/cweidema/bootcamp/tmpdat/RAM/RAM_catFR/RAM_catFR1_power/encoding/hdf5_files_sess/pow_R1375C_2_allleads.hdf5\n",
      "/scratch/cweidema/bootcamp/tmpdat/RAM/RAM_catFR/RAM_catFR1_power/encoding/hdf5_files_sess/pow_R1375C_3_allleads.hdf5\n",
      "/scratch/cweidema/bootcamp/tmpdat/RAM/RAM_catFR/RAM_catFR1_power/encoding/hdf5_files_sess/pow_R1375C_4_allleads.hdf5\n"
     ]
    }
   ],
   "source": [
    "for sesspath in sesspaths:\n",
    "    filename = os.path.split(sesspath)[-1]\n",
    "    subj = filename.split('_')[1]\n",
    "    if subj in subj_done:\n",
    "        continue\n",
    "    subjpowfile = subjpow_path+subj+'_pow.hdf5'\n",
    "    if os.path.exists(subjpowfile):\n",
    "        continue\n",
    "    print('Processing ', subj)\n",
    "    subj_done.append(subj)\n",
    "    subj_files = sorted(glob(os.path.join(sesspow_path,'pow_'+subj+'_[0-9]_allleads.hdf5')))\n",
    "    # there's at least one case of double digit session number ('10'):\n",
    "    subj_files.extend(sorted(glob(os.path.join(sesspow_path,'pow_'+subj+'_[0-9][0-9]_allleads.hdf5'))))\n",
    "    subj_files = np.array(subj_files)\n",
    "    total_events = 0\n",
    "    subjdat_attrs = {}\n",
    "    # attrs_to_copy = ['buffer','baseline','subject','samplerate','exp']\n",
    "    attrs_to_copy = ['buf','subject','samplerate','exp', 'period', 'mirror']\n",
    "    subjdat_keys = {}\n",
    "    keys_to_copy = ['channels','channels_orig','time','freqs']\n",
    "    merged_evs = {}\n",
    "    good_files = True\n",
    "    for s, subjsesspath in enumerate(subj_files):\n",
    "        print(subjsesspath)\n",
    "        sessdat = h5py.File(subjsesspath,'r')\n",
    "        try:\n",
    "            total_events += len(sessdat['events/type'])\n",
    "        except KeyError:\n",
    "            print('Error, deleting', subj_files)\n",
    "            for sf in subj_files:\n",
    "                os.remove(sf)\n",
    "            good_files = False\n",
    "            break\n",
    "        if s == 0:\n",
    "            # subjdat_zmeans = sessdat['zmeans']\n",
    "            # subjdat_zstd = sessdat['zstd']\n",
    "            for attr in attrs_to_copy:\n",
    "                subjdat_attrs[attr] = sessdat['data'].attrs[attr]\n",
    "            subjdat_attrs['session'] = sessdat['data'].attrs['session']\n",
    "            for key in keys_to_copy:\n",
    "                subjdat_keys[key] = sessdat[key]\n",
    "            for evkey in sessdat['events']:\n",
    "                merged_evs[evkey] = sessdat['events'][evkey].value\n",
    "        else:\n",
    "            # subjdat_zmeans = np.dstack([subjdat_zmeans,sessdat['zmeans']])\n",
    "            # subjdat_zstd = np.dstack([subjdat_zstd,sessdat['zstd']])\n",
    "            for attr in attrs_to_copy:\n",
    "                if np.any(\n",
    "                        subjdat_attrs[attr] != sessdat['data'].attrs[attr]):\n",
    "                    raise ValueError(\n",
    "                        'Attribute missmatch: '+str(subjdat_attrs[attr])+'\\n'+\n",
    "                        str(sessdat['data'].attrs[attr])+'\\n'+subjsesspath+'\\n'+\n",
    "                        str(s))\n",
    "                subjdat_attrs['session'] = np.hstack(\n",
    "                    [subjdat_attrs['session'],sessdat['data'].attrs['session']])\n",
    "            for key in keys_to_copy:\n",
    "                if np.any(subjdat_keys[key].value != sessdat[key].value):\n",
    "                    if (key == 'time') and (np.allclose(\n",
    "                            subjdat_keys[key].value, sessdat[key].value,\n",
    "                            rtol=0.001, atol=0.001)):\n",
    "                        continue\n",
    "                    raise ValueError(\n",
    "                        'Key missmatch: '+str(subjdat_keys[key])+'\\n'+\n",
    "                        str(sessdat[key])+'\\n'+subjsesspath+'\\n'+\n",
    "                        str(s))\n",
    "            for evkey in sessdat['events']:\n",
    "                try:\n",
    "                    merged_evs[evkey] = np.hstack(\n",
    "                        [merged_evs[evkey],sessdat['events'][evkey]])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "                except ValueError as e:\n",
    "                    if evkey == 'stim_params':\n",
    "                        merged_evs.pop(evkey)\n",
    "                    else:\n",
    "                        raise e\n",
    "    if not good_files:\n",
    "        continue\n",
    "    merged_shape = list(sessdat['data'].shape)\n",
    "    merged_shape[2] = total_events\n",
    "    subjdat = h5py.File(subjpowfile,'w-',libver='latest')\n",
    "    subjdat_data = subjdat.create_dataset('data',merged_shape)\n",
    "    # subjdat_zmeans = subjdat.create_dataset('zmeans',data=subjdat_zmeans)\n",
    "    # subjdat_zstd = subjdat.create_dataset('zstd', data=subjdat_zstd)\n",
    "    for key in keys_to_copy:\n",
    "        subjdat_keys[key] = subjdat.create_dataset(key,data=subjdat_keys[key])\n",
    "    ev_indx = 0\n",
    "    for s,subjsesspath in enumerate(subj_files):\n",
    "        sessdat = h5py.File(subjsesspath,'r')\n",
    "        ev_len = len(sessdat['events/type'])\n",
    "        subjdat_data[:,:,ev_indx:ev_indx+ev_len,:] = sessdat['data']\n",
    "        ev_indx += ev_len\n",
    "        if s == 0:\n",
    "            #subjdat.copy(sessdat['events'],subjdat)\n",
    "            if 'tal_struct' in sessdat:\n",
    "                subjdat.copy(sessdat['tal_struct'], subjdat)\n",
    "            elif 'h5info' in sessdat:\n",
    "                subjdat.copy(sessdat['h5info'], subjdat)\n",
    "            else:\n",
    "                raise ValueError('Missing location data')\n",
    "            subjdat.create_group('events')\n",
    "            for evkey in merged_evs:\n",
    "                subjdat['events/'+evkey] = merged_evs[evkey]\n",
    "    for attr in attrs_to_copy:\n",
    "        subjdat_data.attrs[attr] = subjdat_attrs[attr]\n",
    "        \n",
    "    subjdat_data.dims[0].label = 'channels'\n",
    "    # pfile['channels'] = channels\n",
    "    subjdat_data.dims.create_scale(subjdat['channels'], 'channels')\n",
    "    subjdat_data.dims[0].attach_scale(subjdat['channels'])\n",
    "    #\n",
    "    subjdat_data.dims[1].label = 'freqs'\n",
    "    # pfile['freqs'] = freqs\n",
    "    subjdat_data.dims.create_scale(subjdat['freqs'], 'freqs')\n",
    "    subjdat_data.dims[1].attach_scale(subjdat['freqs'])\n",
    "    subjdat_data.dims[3].label = 'time'\n",
    "    # pfile['time'] = times\n",
    "    subjdat_data.dims.create_scale(subjdat['time'], 'time')\n",
    "    subjdat_data.dims[3].attach_scale(subjdat['time'])\n",
    "    subjdat_data.dims[2].label = 'events'\n",
    "    for evkey in subjdat['events']: #events.dtype.names:\n",
    "        subjdat_data.dims.create_scale(subjdat['events/'+evkey], evkey)\n",
    "        subjdat_data.dims[2].attach_scale(subjdat['events/'+evkey])\n",
    "    subjdat.close()\n",
    "    # make file read only to avoid accidental loss:\n",
    "    os.chmod(subjpowfile,0o444)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PTSA",
   "language": "python",
   "name": "ptsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
