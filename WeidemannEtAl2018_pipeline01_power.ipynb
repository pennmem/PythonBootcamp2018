{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ptsa.data.filters.MorletWaveletFilter import MorletWaveletFilter\n",
    "from ptsa.data.readers import EEGReader\n",
    "from ptsa.data.filters import MonopolarToBipolarMapper\n",
    "from ptsa.data.filters import ResampleFilter\n",
    "from ptsa.data.filters import ButterworthFilter\n",
    "# from ptsa.data.readers.TalReader import TalReader\n",
    "from ptsa.data.readers import TalReader\n",
    "# from ptsa.data.readers.IndexReader import JsonIndexReader\n",
    "from ptsa.data.readers import JsonIndexReader\n",
    "from ptsa.data.readers import BaseEventReader\n",
    "from ptsa.data.TimeSeriesX import TimeSeriesX as TimeSeries\n",
    "import h5py\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_on_rhino = True\n",
    "\n",
    "if run_on_rhino:\n",
    "    rhino_mount = ''\n",
    "else:\n",
    "    rhino_mount = '/home/ctw/fusemounts/rhino'\n",
    "\n",
    "# evfile_date = '20180109'\n",
    "output_root = '/scratch/cweidema/bootcamp/tmpdat'\n",
    "\n",
    "pow_params = {\n",
    "    'catFR1': {\n",
    "        'encoding': {\n",
    "            'output_path': (rhino_mount+output_root+'/RAM/RAM_catFR/'+\n",
    "                            'RAM_catFR1_power/encoding/hdf5_files_sess'),\n",
    "            # 'ev_file': (rhino_mount+\n",
    "            #             '/home1/cweidema/Christoph/Analyses/RAM/RAM_catFR/'+\n",
    "            #             'data/RAM_catFR1_events'+evfile_date+'_jim.npy'),\n",
    "            'mirror': False,\n",
    "            'start_time': -0.5,\n",
    "            'end_time': 2.1,\n",
    "            'buf': 1.0,\n",
    "            # 'evfilt': ev['type']=='WORD'\n",
    "            'ev_type': ['WORD']\n",
    "        },\n",
    "        'retrieval': {\n",
    "            'output_path': (rhino_mount+output_root+'/scratch/cweidema/RAM/RAM_catFR/'+\n",
    "                            'RAM_catFR1_power/retrieval/hdf5_files_sess'),\n",
    "            # 'ev_file': (rhino_mount+\n",
    "            #             '/home1/cweidema/Christoph/Analyses/RAM/RAM_catFR/'+\n",
    "            #             'data/RAM_catFR1_events'+evfile_date+'_jim.npy'),\n",
    "            'mirror': True,\n",
    "            'start_time': -0.9,\n",
    "            'end_time': -0.1,\n",
    "            'buf': 0.76,\n",
    "            # 'evfilt': ((ev['type']=='REC_WORD') |\n",
    "            #            (ev['type']=='REC_BASE'))\n",
    "            'ev_type': ['REC_WORD', 'REC_BASE']\n",
    "        }\n",
    "    },\n",
    "    'FR1': {\n",
    "        'encoding': {\n",
    "            'output_path': (rhino_mount+output_root+'/scratch/cweidema/RAM/RAM_FR/'+\n",
    "                            'RAM_FR1_power/encoding/hdf5_files_sess'),\n",
    "            # 'ev_file': (rhino_mount+\n",
    "            #             '/home1/cweidema/Christoph/Analyses/RAM/RAM_FR/'+\n",
    "            #             'data/RAM_FR1_events'+evfile_date+'_jim.npy'),\n",
    "            'mirror': False,\n",
    "            'start_time': -0.5,\n",
    "            'end_time': 2.1,\n",
    "            'buf': 1.0,\n",
    "            # 'evfilt': ev['type']=='WORD'\n",
    "            'ev_type': ['WORD']\n",
    "        },\n",
    "        'retrieval': {\n",
    "            'output_path': (rhino_mount+output_root+'/scratch/cweidema/RAM/RAM_FR/'+\n",
    "                            'RAM_FR1_power/retrieval/hdf5_files_sess'),\n",
    "            # 'ev_file': (rhino_mount+\n",
    "            #             '/home1/cweidema/Christoph/Analyses/RAM/RAM_FR/'+\n",
    "            #             'data/RAM_FR1_events'+evfile_date+'_jim.npy'),\n",
    "            'mirror': True,\n",
    "            'start_time': -0.9,\n",
    "            'end_time': -0.1,\n",
    "            'buf': 0.76,\n",
    "            # 'evfilt': ((ev['type']=='REC_WORD') |\n",
    "            #            (ev['type']=='REC_BASE'))\n",
    "            'ev_type': ['REC_WORD', 'REC_BASE']\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINEFILT = [58, 62]\n",
    "POWHZ = 50.\n",
    "FREQS = np.logspace(np.log10(3),np.log10(180), 8)\n",
    "\n",
    "jr = JsonIndexReader(rhino_mount + '/protocols/r1.json')\n",
    "\n",
    "atlas_defaults = {'id': ('', np.str), 'region': ('', np.str), 'x': (np.nan, np.float),\n",
    "                  'y': (np.nan, np.float), 'z': (np.nan, np.float)}\n",
    "\n",
    "\n",
    "# not sure what's wrong with this subject\n",
    "bad_subjects = ['R1135E', 'R1221P', 'R1247P', 'R1269E', 'R1348J', 'R1366J', 'R1370E', 'R1372C',\n",
    "                'R1004D', 'R1226D']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_sess(exp, period, ev):\n",
    "    if len(np.unique(ev['subject'])) != 1:\n",
    "        raise ValueError('Invalid subject ' + str(np.unique(ev['subject'])))\n",
    "    if len(np.unique(ev['session'])) != 1:\n",
    "        raise ValueError('Invalid session ' + str(np.unique(ev['session'])))\n",
    "    subj = ev['subject'][0]\n",
    "    if subj in bad_subjects:\n",
    "        return\n",
    "    sess = ev['session'][0]\n",
    "    pdir = pow_params[exp][period]['output_path']\n",
    "    pfile_path = os.path.join(pdir,'pow_'+subj+'_'+str(sess)+'_allleads.hdf5')\n",
    "    if not os.path.exists(pdir):\n",
    "        try:\n",
    "            os.makedirs(pdir)\n",
    "        except OSError as e:\n",
    "            print('no problem', e)\n",
    "            pass\n",
    "    elif os.path.exists(pfile_path):\n",
    "        # print pfile_path,'exists!'\n",
    "        return\n",
    "    try:\n",
    "        pfile = h5py.File(pfile_path, 'w-', libver='latest')\n",
    "    except IOError:\n",
    "        print('Cannot create', pfile_path)\n",
    "        return\n",
    "    print('Processing exp, period, subject, session: ', exp, period, subj, sess)\n",
    "\n",
    "    hdf5 = True\n",
    "    if ev['eegfile'][0].split('.')[-1] != 'h5':\n",
    "        try:\n",
    "            pairs_path = jr.get_value('pairs', subject=subj,\n",
    "                                      experiment=exp, session=sess)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            pfile.close()\n",
    "            print('removing', pfile_path)\n",
    "            os.remove(pfile_path)\n",
    "            return\n",
    "        tal_reader = TalReader(filename=pairs_path)\n",
    "        channels = tal_reader.get_monopolar_channels()\n",
    "        hdf5 = False\n",
    "    else:\n",
    "        channels = np.array([])\n",
    "    if pow_params[exp][period]['mirror']:\n",
    "        dat = EEGReader(events=ev.view(np.recarray),\n",
    "                        channels=channels,\n",
    "                        start_time=pow_params[exp][period]['start_time'],\n",
    "                        end_time=pow_params[exp][period]['end_time'],\n",
    "                        buffer_time=0.0).read()\n",
    "        dat = dat.add_mirror_buffer(pow_params[exp][period]['buf'])\n",
    "    else:\n",
    "        dat = EEGReader(events=ev.view(np.recarray),\n",
    "                        channels=channels,\n",
    "                        start_time=pow_params[exp][period]['start_time'],\n",
    "                        end_time=pow_params[exp][period]['end_time'],\n",
    "                        buffer_time=pow_params[exp][period]['buf']).read()\n",
    "    if not 'bipolar_pairs' in dat.coords:\n",
    "        if hdf5:\n",
    "            # need to figure out how to get bipolar here!\n",
    "            return\n",
    "        dat = MonopolarToBipolarMapper(\n",
    "            time_series=dat, bipolar_pairs=tal_reader.get_bipolar_pairs()).filter()\n",
    "    if hdf5:\n",
    "        channels = dat.bipolar_pairs.values\n",
    "    # set mean to zero to reduce edge effects / ringing in later\n",
    "    # processing steps:\n",
    "    dat -= dat.mean('time')\n",
    "    # Notch Butterworth filter for 60Hz line noise:\n",
    "    dat = ButterworthFilter(time_series=dat, freq_range=LINEFILT,\n",
    "                            filt_type='stop', order=4).filter()\n",
    "    dat, _ = MorletWaveletFilter(\n",
    "        time_series=dat, freqs=FREQS, output='power', frequency_dim_pos=0,\n",
    "        width=5, verbose=True).filter()\n",
    "    dat = np.log10(dat)\n",
    "    dat = TimeSeries(dat, coords=dat.coords)\n",
    "    dat = ResampleFilter(time_series=dat, resamplerate=POWHZ).filter()\n",
    "    dat = dat.remove_buffer(duration=pow_params[exp][period]['buf'])\n",
    "    data = pfile.create_dataset(\n",
    "        'data', data=dat.values, compression='gzip', compression_opts=9)\n",
    "    # finalize HDF5 file:\n",
    "    for param in pow_params[exp][period]:\n",
    "        try:\n",
    "            data.attrs[param] = pow_params[exp][period][param]\n",
    "        except TypeError:\n",
    "            data.attrs[param] = [str.encode(s) for s in pow_params[exp][period][param]]\n",
    "    data.attrs['period'] = period\n",
    "    try:\n",
    "        data.attrs['subject'] = subj\n",
    "    except TypeError:\n",
    "        data.attrs['subject'] = str.encode(subj)\n",
    "    data.attrs['session'] = sess\n",
    "    data.attrs['samplerate'] = np.float(dat.samplerate)\n",
    "    try:\n",
    "        data.attrs['exp'] = exp\n",
    "    except TypeError:\n",
    "        data.attrs['exp'] = str.encode(exp)\n",
    "    if not hdf5:\n",
    "        pfile['tal_struct/tag_name'] = [\n",
    "            str.encode(tn) for tn in tal_reader.tal_struct_array['tagName']]\n",
    "        atlases = {}\n",
    "        for chan in tal_reader.tal_struct_array['atlases']:\n",
    "            # make sure we get all atlases across channels\n",
    "            for atls in chan:\n",
    "                if not atls in atlases:\n",
    "                    atlases[atls] = {key: [] for key in atlas_defaults}   \n",
    "        for chan in tal_reader.tal_struct_array['atlases']:\n",
    "            for atls in atlases:\n",
    "                for key in atlas_defaults:\n",
    "                    if atls in chan:\n",
    "                        if key in chan[atls]:\n",
    "                            try:\n",
    "                                val = atlas_defaults[key][1](chan[atls][key])\n",
    "                            except TypeError:\n",
    "                                val = atlas_defaults[key][0]\n",
    "                            atlases[atls][key].append(val)\n",
    "                        else:\n",
    "                            atlases[atls][key].append(atlas_defaults[key][0])\n",
    "                    else:\n",
    "                        atlases[atls][key].append(atlas_defaults[key][0])\n",
    "        for atls in atlases:\n",
    "            for key in atlases[atls]:\n",
    "                pfile['tal_struct/atlases/'+atls+'/'+key] = atlases[atls][key]\n",
    "        pfile['tal_struct/code'] = [\n",
    "            str(c) for c in tal_reader.tal_struct_array['code']]\n",
    "        pfile['tal_struct/channel_1'] = tal_reader.tal_struct_array['channel_1']\n",
    "        pfile['tal_struct/channel_2'] = tal_reader.tal_struct_array['channel_2']\n",
    "        if 'is_explicit' in tal_reader.tal_struct_array.dtype.names:\n",
    "            pfile['tal_struct/is_explicit'] = tal_reader.tal_struct_array['is_explicit']\n",
    "        pfile['tal_struct/type_1'] = [\n",
    "            str(t) for t in tal_reader.tal_struct_array['type_1']]\n",
    "        pfile['tal_struct/type_2'] = [\n",
    "            str(t) for t in tal_reader.tal_struct_array['type_2']]\n",
    "        if 'is_stim_only' in tal_reader.tal_struct_array.dtype.names:\n",
    "            pfile['tal_struct/is_stim_only'] = tal_reader.tal_struct_array['is_stim_only']\n",
    "        if 'id' in tal_reader.tal_struct_array.dtype.names:\n",
    "            pfile['tal_struct/id'] = [\n",
    "                str(i) for i in tal_reader.tal_struct_array['id']]\n",
    "        pfile['tal_struct/channel'] = np.array(\n",
    "            [np.int16(c) for c in tal_reader.tal_struct_array['channel']])\n",
    "        pfile['tal_struct/eType'] = [\n",
    "            str(t) for t in tal_reader.tal_struct_array['eType']]\n",
    "        if hasattr(tal_reader, 'struct_type'):\n",
    "            pfile['tal_struct/struct_type'] = tal_reader.struct_type\n",
    "        pfile['tal_struct/struct_name'] = tal_reader.struct_name\n",
    "        pfile['tal_struct/filename'] = tal_reader.filename\n",
    "    else:\n",
    "        h5group = pfile.create_group('h5info')\n",
    "        h5dat = h5py.File(ev['eegfile'][0], 'r')\n",
    "        h5dat.copy('bipolar_info', h5group)\n",
    "        h5dat.copy('names', h5group)\n",
    "        h5dat.copy('ports', h5group)\n",
    "        h5dat.copy('sense_channel_info', h5group)\n",
    "        \n",
    "    data.dims[0].label = 'freqs'\n",
    "    pfile['freqs'] = dat.frequency.values\n",
    "    data.dims.create_scale(pfile['freqs'], 'freqs')\n",
    "    data.dims[0].attach_scale(pfile['freqs'])\n",
    "\n",
    "    data.dims[1].label = 'channels'\n",
    "    pfile['channels_orig'] = channels # possibly monopolar\n",
    "    if not hdf5:\n",
    "        pfile['channels'] = pfile['tal_struct/id']\n",
    "    else:\n",
    "        pfile['channels'] = pfile['h5info/sense_channel_info/contact_name']\n",
    "    # bipolar:\n",
    "    data.dims.create_scale(pfile['channels'], 'channels')\n",
    "    data.dims[1].attach_scale(pfile['channels'])\n",
    "    #\n",
    "    data.dims[3].label = 'time'\n",
    "    pfile['time'] = dat['time'].values\n",
    "    data.dims.create_scale(pfile['time'], 'time')\n",
    "    data.dims[3].attach_scale(pfile['time'])\n",
    "    data.dims[2].label = 'events'\n",
    "    events = dat['events'].values\n",
    "    for dtn in events.dtype.names:\n",
    "        if events[dtn].dtype == np.object:\n",
    "            continue\n",
    "        if events[dtn].dtype.char == 'U':\n",
    "            pfile['events/'+dtn] = [str.encode(e) for e in events[dtn]]\n",
    "        else:\n",
    "            pfile['events/'+dtn] = events[dtn]\n",
    "        data.dims.create_scale(pfile['events/'+dtn], dtn)\n",
    "        data.dims[2].attach_scale(pfile['events/'+dtn])\n",
    "    pfile.close()\n",
    "    # make file read only to avoid accidental loss:\n",
    "    os.chmod(pfile_path,0o444)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing exp, period, subject, session:  catFR1 encoding R1374T 0\n",
      "looking for /protocols/r1/subjects/R1374T/experiments/catFR1/sessions/0/ephys/current_processed/noreref/sources.json\n",
      "looking for /protocols/r1/subjects/R1374T/experiments/catFR1/sessions/0/ephys/current_processed/noreref/../sources.json\n",
      "looking for /protocols/r1/subjects/R1374T/experiments/catFR1/sessions/0/ephys/current_processed/noreref/sources.json\n",
      "looking for /protocols/r1/subjects/R1374T/experiments/catFR1/sessions/0/ephys/current_processed/noreref/../sources.json\n",
      "total time wavelet loop:  48.152819871902466\n",
      "230\n",
      "Processing exp, period, subject, session:  catFR1 encoding R1374T 1\n",
      "looking for /protocols/r1/subjects/R1374T/experiments/catFR1/sessions/1/ephys/current_processed/noreref/sources.json\n",
      "looking for /protocols/r1/subjects/R1374T/experiments/catFR1/sessions/1/ephys/current_processed/noreref/../sources.json\n",
      "looking for /protocols/r1/subjects/R1374T/experiments/catFR1/sessions/1/ephys/current_processed/noreref/sources.json\n",
      "looking for /protocols/r1/subjects/R1374T/experiments/catFR1/sessions/1/ephys/current_processed/noreref/../sources.json\n",
      "total time wavelet loop:  45.558152198791504\n",
      "230\n",
      "Processing exp, period, subject, session:  catFR1 encoding R1375C 1\n",
      "looking for /protocols/r1/subjects/R1375C/experiments/catFR1/sessions/1/ephys/current_processed/noreref/sources.json\n",
      "looking for /protocols/r1/subjects/R1375C/experiments/catFR1/sessions/1/ephys/current_processed/noreref/../sources.json\n",
      "looking for /protocols/r1/subjects/R1375C/experiments/catFR1/sessions/1/ephys/current_processed/noreref/sources.json\n",
      "looking for /protocols/r1/subjects/R1375C/experiments/catFR1/sessions/1/ephys/current_processed/noreref/../sources.json\n",
      "total time wavelet loop:  48.36342716217041\n",
      "230\n",
      "Processing exp, period, subject, session:  catFR1 encoding R1375C 2\n",
      "looking for /protocols/r1/subjects/R1375C/experiments/catFR1/sessions/2/ephys/current_processed/noreref/sources.json\n",
      "looking for /protocols/r1/subjects/R1375C/experiments/catFR1/sessions/2/ephys/current_processed/noreref/../sources.json\n",
      "looking for /protocols/r1/subjects/R1375C/experiments/catFR1/sessions/2/ephys/current_processed/noreref/sources.json\n",
      "looking for /protocols/r1/subjects/R1375C/experiments/catFR1/sessions/2/ephys/current_processed/noreref/../sources.json\n",
      "total time wavelet loop:  48.35398626327515\n",
      "230\n",
      "Processing exp, period, subject, session:  catFR1 encoding R1375C 3\n",
      "looking for /protocols/r1/subjects/R1375C/experiments/catFR1/sessions/3/ephys/current_processed/noreref/sources.json\n",
      "looking for /protocols/r1/subjects/R1375C/experiments/catFR1/sessions/3/ephys/current_processed/noreref/../sources.json\n",
      "looking for /protocols/r1/subjects/R1375C/experiments/catFR1/sessions/3/ephys/current_processed/noreref/sources.json\n",
      "looking for /protocols/r1/subjects/R1375C/experiments/catFR1/sessions/3/ephys/current_processed/noreref/../sources.json\n",
      "total time wavelet loop:  49.25315070152283\n",
      "230\n",
      "Processing exp, period, subject, session:  catFR1 encoding R1375C 4\n",
      "looking for /protocols/r1/subjects/R1375C/experiments/catFR1/sessions/4/ephys/current_processed/noreref/sources.json\n",
      "looking for /protocols/r1/subjects/R1375C/experiments/catFR1/sessions/4/ephys/current_processed/noreref/../sources.json\n",
      "looking for /protocols/r1/subjects/R1375C/experiments/catFR1/sessions/4/ephys/current_processed/noreref/sources.json\n",
      "looking for /protocols/r1/subjects/R1375C/experiments/catFR1/sessions/4/ephys/current_processed/noreref/../sources.json\n",
      "total time wavelet loop:  47.74685096740723\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "for exp in ['catFR1']:  # pow_params:\n",
    "    ev1 = []\n",
    "    ev2 = []\n",
    "    ev3 = []\n",
    "    for f in jr.aggregate_values('task_events', experiment=exp):\n",
    "        tmpev = BaseEventReader(filename=f).read()\n",
    "        if 'recognized' in tmpev.dtype.names:\n",
    "            ev1.append(tmpev)\n",
    "        elif 'phase' in tmpev.dtype.names:\n",
    "            ev2.append(tmpev)\n",
    "        else:\n",
    "            ev3.append(tmpev)\n",
    "    ev1 = np.concatenate(ev1)\n",
    "    ev2 = np.concatenate(ev2)\n",
    "    ev3 = np.concatenate(ev3)\n",
    "    for period in ['encoding']: #pow_params[exp]:\n",
    "        ev = np.concatenate([ev1[list(ev3.dtype.names)],\n",
    "                             ev2[list(ev3.dtype.names)], ev3])\n",
    "        # ev = np.concatenate(\n",
    "        #     [BaseEventReader(filename=f).read() for f\n",
    "        #      in jr.aggregate_values('task_events',\n",
    "        #                             experiment=exp)])\n",
    "        # ev = np.load(pow_params[exp][period]['ev_file'])\n",
    "        evfilt = np.array([e in pow_params[exp][period]['ev_type']\n",
    "                           for e in ev['type']])\n",
    "        ev = ev[evfilt]\n",
    "        for subj in ['R1374T', 'R1375C']:  # np.unique(ev['subject']):\n",
    "            subjfilt = ev['subject']==subj\n",
    "            for sess in np.unique(ev[subjfilt]['session']): #sessions:\n",
    "                sessfilt = ev['session'] == sess\n",
    "                if num_mp_procs > 0:\n",
    "                    res.append(po.apply_async(\n",
    "                        proc_sess, [exp, period, ev[subjfilt & sessfilt]]))\n",
    "                else:\n",
    "                    proc_sess(exp, period, ev[subjfilt & sessfilt])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PTSA",
   "language": "python",
   "name": "ptsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
